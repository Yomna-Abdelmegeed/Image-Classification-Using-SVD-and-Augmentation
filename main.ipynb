{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf7e75cd",
   "metadata": {},
   "source": [
    "# **Image Classification Using SVD**  \n",
    "### **Python Code for Image Classification Using Singular Value Decomposition and Optimization**\n",
    "\n",
    "#### Authors: * yomna abdelmegeed , nadia Ashraf , monica maged , yara ahmed , hagar atef , menna alla ahmed*\n",
    "\n",
    "---\n",
    "\n",
    "### Overview  \n",
    "This repository contains Python code accompanying our paper:  \n",
    "[**Image Classification Using Singular Value Decomposition and Optimization**](https://arxiv.org/pdf/2412.07288).\n",
    "\n",
    "This code demonstrates the implementation of our proposed method for image classification using singular value decomposition (SVD) and optimized categorical representative images.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebc53fc",
   "metadata": {},
   "source": [
    "## Outline of the Code:\n",
    "\n",
    "\n",
    "1.   Import packages & connect to drive\n",
    "2.   Image pre-processing\n",
    "3.   Split data into training and testing\n",
    "4.   Compute templates with training set\n",
    "5.   Classification probability distribution and errors with different ranks and norms, testing against optimally weighted template\n",
    "6.   Norm evaluation at a best rank\n",
    "7.   Original test images with predicted labels for Fro norm rank 10\n",
    "8.   Generate subplot showing best rank images for one persian cat and boxer dog test for each norm\n",
    "9.   Further comparison of optimally weighted template vs average template\n",
    "10.  Single image experiments\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e03ab2f",
   "metadata": {},
   "source": [
    "## 1. Import Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62f507f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from skimage.exposure import equalize_hist\n",
    "from skimage import io, color\n",
    "from skimage.transform import rotate\n",
    "from skimage.transform import resize\n",
    "from skimage.transform import rescale\n",
    "from skimage.exposure import adjust_gamma\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from numpy.linalg import svd\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7405e0c3",
   "metadata": {},
   "source": [
    "## 2. Image Pre-Processing\n",
    "### Resize and Convert to Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "444a82d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to the folders containing images\n",
    "boxer_folder = 'boxer'\n",
    "persian_cat_folder = 'persian_cat'\n",
    "\n",
    "#image_size = (256, 256)  # Resize all images to this size\n",
    "image_size = (64, 64) \n",
    "\n",
    "# Function to load and preprocess images from a folder\n",
    "def load_images(folder_path, image_size):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(('.jpg', '.JPG', '.jpeg')):\n",
    "            img = io.imread(os.path.join(folder_path, filename))\n",
    "\n",
    "            # Ensure the image is RGB (3 channels) by removing an alpha channel if it exists\n",
    "            if img.shape[-1] == 4:\n",
    "                img = img[..., :3]  # Keep only the first 3 channels (RGB)\n",
    "\n",
    "            img_gray = color.rgb2gray(img)  # Convert to grayscale\n",
    "            img_resized = resize(img_gray, image_size)  # Resize\n",
    "            images.append(img_resized)  # Store resized image\n",
    "    return np.array(images)  # converts the list of images to a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1473a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to augment images with rotations/flips and zooms (*4)\n",
    "def augment_images(images):\n",
    "    augmented = []\n",
    "    for img in images:\n",
    "        augmented.append(img)\n",
    "        augmented.append(rotate(img, angle=10))\n",
    "        augmented.append(np.fliplr(img))\n",
    "        #  zoom by 30%\n",
    "        zoomed = rescale(img, 1.3, mode='reflect', anti_aliasing=True)\n",
    "        # crop zoomed image\n",
    "        center = zoomed.shape[0] // 2\n",
    "        cropped = zoomed[center - 32:center + 32, center - 32:center + 32]\n",
    "        augmented.append(cropped)\n",
    "    return np.array(augmented)\n",
    "    \n",
    "\n",
    "# Load images\n",
    "boxer_images = load_images(boxer_folder, image_size)\n",
    "persian_cat_images = load_images(persian_cat_folder, image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522af9a0",
   "metadata": {},
   "source": [
    "## 3. Split data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e0f756",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = np.concatenate([persian_cat_images, boxer_images])\n",
    "labels = np.concatenate([np.zeros(len(persian_cat_images)), np.ones(len(boxer_images))])\n",
    "\n",
    "# Stratified split (preserve class distribution)\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=123)\n",
    "train_idx, test_idx = next(sss.split(all_images, labels))\n",
    "\n",
    "# Split data\n",
    "persian_cat_train = all_images[train_idx][labels[train_idx] == 0]\n",
    "boxer_train = all_images[train_idx][labels[train_idx] == 1]\n",
    "persian_cat_test = all_images[test_idx][labels[test_idx] == 0]\n",
    "boxer_test = all_images[test_idx][labels[test_idx] == 1]\n",
    "\n",
    "# --- Added: Apply augmentation to training data only ---\n",
    "boxer_train = augment_images(boxer_train)\n",
    "persian_cat_train = augment_images(persian_cat_train)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --- NEW: Shuffle the training data ---\n",
    "np.random.shuffle(boxer_train)\n",
    "np.random.shuffle(persian_cat_train)\n",
    "\n",
    "print(\"Training and testing split completed:\")\n",
    "print(f\"Persian Cat Training: {persian_cat_train.shape}\")  # Will show 4x original size\n",
    "print(f\"Persian Cat Testing: {persian_cat_test.shape}\")\n",
    "print(f\"Boxer Training: {boxer_train.shape}\")              # Will show 4x original size\n",
    "print(f\"Boxer Testing: {boxer_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e4c38b",
   "metadata": {},
   "source": [
    "## 4. Compute templates with training set\n",
    "### Average template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c96b56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
