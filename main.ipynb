{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf7e75cd",
   "metadata": {},
   "source": [
    "# **Image Classification Using SVD**  \n",
    "### **Python Code for Image Classification Using Singular Value Decomposition and Optimization**\n",
    "\n",
    "#### Authors: * yomna abdelmegeed , nadia Ashraf , monica maged , yara ahmed , hagar atef , menna alla ahmed*\n",
    "\n",
    "---\n",
    "\n",
    "### Overview  \n",
    "This repository contains Python code accompanying our paper:  \n",
    "[**Image Classification Using Singular Value Decomposition and Optimization**](https://arxiv.org/pdf/2412.07288).\n",
    "\n",
    "This code demonstrates the implementation of our proposed method for image classification using singular value decomposition (SVD) and optimized categorical representative images.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebc53fc",
   "metadata": {},
   "source": [
    "## Outline of the Code:\n",
    "\n",
    "\n",
    "1.   Import packages & connect to drive\n",
    "2.   Image pre-processing\n",
    "3.   Split data into training and testing\n",
    "4.   Compute templates with training set\n",
    "5.   Classification probability distribution and errors with different ranks and norms, testing against optimally weighted template\n",
    "6.   Norm evaluation at a best rank\n",
    "7.   Original test images with predicted labels for Fro norm rank 10\n",
    "8.   Generate subplot showing best rank images for one persian cat and boxer dog test for each norm\n",
    "9.   Further comparison of optimally weighted template vs average template\n",
    "10.  Single image experiments\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e03ab2f",
   "metadata": {},
   "source": [
    "## 1. Import Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62f507f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from skimage.exposure import equalize_hist\n",
    "from skimage import io, color\n",
    "from skimage.transform import rotate\n",
    "from skimage.transform import resize\n",
    "from skimage.transform import rescale\n",
    "from skimage.exposure import adjust_gamma\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from numpy.linalg import svd\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7405e0c3",
   "metadata": {},
   "source": [
    "## 2. Image Pre-Processing\n",
    "### Resize and Convert to Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "444a82d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to the folders containing images\n",
    "boxer_folder = 'boxer'\n",
    "persian_cat_folder = 'persian_cat'\n",
    "\n",
    "#image_size = (256, 256)  # Resize all images to this size\n",
    "image_size = (64, 64) \n",
    "\n",
    "# Function to load and preprocess images from a folder\n",
    "def load_images(folder_path, image_size):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(('.jpg', '.JPG', '.jpeg')):\n",
    "            img = io.imread(os.path.join(folder_path, filename))\n",
    "\n",
    "            # Ensure the image is RGB (3 channels) by removing an alpha channel if it exists\n",
    "            if img.shape[-1] == 4:\n",
    "                img = img[..., :3]  # Keep only the first 3 channels (RGB)\n",
    "\n",
    "            img_gray = color.rgb2gray(img)  # Convert to grayscale\n",
    "            img_resized = resize(img_gray, image_size)  # Resize\n",
    "            images.append(img_resized)  # Store resized image\n",
    "    return np.array(images)  # converts the list of images to a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1473a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to augment images with rotations/flips and zooms (*4)\n",
    "def augment_images(images):\n",
    "    augmented = []\n",
    "    for img in images:\n",
    "        augmented.append(img)\n",
    "        augmented.append(rotate(img, angle=10))\n",
    "        augmented.append(np.fliplr(img))\n",
    "        #  zoom by 30%\n",
    "        zoomed = rescale(img, 1.3, mode='reflect', anti_aliasing=True)\n",
    "        # crop zoomed image\n",
    "        center = zoomed.shape[0] // 2\n",
    "        cropped = zoomed[center - 32:center + 32, center - 32:center + 32]\n",
    "        augmented.append(cropped)\n",
    "    return np.array(augmented)\n",
    "    \n",
    "\n",
    "# Load images\n",
    "boxer_images = load_images(boxer_folder, image_size)\n",
    "persian_cat_images = load_images(persian_cat_folder, image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522af9a0",
   "metadata": {},
   "source": [
    "## 3. Split data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e0f756",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = np.concatenate([persian_cat_images, boxer_images])\n",
    "labels = np.concatenate([np.zeros(len(persian_cat_images)), np.ones(len(boxer_images))])\n",
    "\n",
    "# Stratified split (preserve class distribution)\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=123)\n",
    "train_idx, test_idx = next(sss.split(all_images, labels))\n",
    "\n",
    "# Split data\n",
    "persian_cat_train = all_images[train_idx][labels[train_idx] == 0]\n",
    "boxer_train = all_images[train_idx][labels[train_idx] == 1]\n",
    "persian_cat_test = all_images[test_idx][labels[test_idx] == 0]\n",
    "boxer_test = all_images[test_idx][labels[test_idx] == 1]\n",
    "\n",
    "# --- Added: Apply augmentation to training data only ---\n",
    "boxer_train = augment_images(boxer_train)\n",
    "persian_cat_train = augment_images(persian_cat_train)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --- NEW: Shuffle the training data ---\n",
    "np.random.shuffle(boxer_train)\n",
    "np.random.shuffle(persian_cat_train)\n",
    "\n",
    "print(\"Training and testing split completed:\")\n",
    "print(f\"Persian Cat Training: {persian_cat_train.shape}\")  # Will show 4x original size\n",
    "print(f\"Persian Cat Testing: {persian_cat_test.shape}\")\n",
    "print(f\"Boxer Training: {boxer_train.shape}\")              # Will show 4x original size\n",
    "print(f\"Boxer Testing: {boxer_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e4c38b",
   "metadata": {},
   "source": [
    "## 4. Compute templates with training set\n",
    "### Average template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c96b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the average template for each category\n",
    "def compute_template(images):\n",
    "    # Average the images to create a representative template\n",
    "    avg_image = np.mean(images, axis=0)\n",
    "    return avg_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfc18b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the average template for each category\n",
    "boxer_a_template = compute_template(boxer_train)\n",
    "persian_cat_a_template = compute_template(persian_cat_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9404525",
   "metadata": {},
   "source": [
    "### Optimized template using SLSQP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bbcb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute weighted template using optimization\n",
    "def compute_weighted_template(images, class_name=\"\"):\n",
    "    # Flatten images to vectors\n",
    "    flattened_images = images.reshape(images.shape[0], -1)\n",
    "    N = flattened_images.shape[0]\n",
    "\n",
    "    # Objective function to minimize reconstruction error for all images\n",
    "    def objective(weights):\n",
    "        weights = np.array(weights)\n",
    "        weighted_avg = np.dot(weights, flattened_images)\n",
    "        total_error = np.sum([\n",
    "            np.linalg.norm(flattened_images[i] - weighted_avg)**2 for i in range(N)\n",
    "        ])\n",
    "        return total_error\n",
    "\n",
    "    # Constraints: weights must sum to 1, and each weight >= 0\n",
    "    constraints = [\n",
    "        {'type': 'eq', 'fun': lambda w: np.sum(w) - 1},  # Sum of weights = 1\n",
    "        {'type': 'ineq', 'fun': lambda w: w}  # Each weight >= 0\n",
    "    ]\n",
    "    initial_weights = np.ones(N) / N  # Uniform initialization\n",
    "\n",
    "    # Solve the optimization problem\n",
    "    result = minimize(objective, initial_weights, constraints=constraints)\n",
    "    optimized_weights = result.x\n",
    "\n",
    "    # Compute the weighted template\n",
    "    weighted_template = np.dot(optimized_weights, flattened_images).reshape(image_size)\n",
    "    print(f\"\\nCompare the Weighted and Average Template for {class_name}\")\n",
    "    print(\"Sum of difference of weights: \")\n",
    "    print(np.sum(optimized_weights - initial_weights))\n",
    "\n",
    "    return weighted_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e898d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the weighted average template for each category\n",
    "boxer_weighted_template = compute_weighted_template(boxer_train, \"Boxer Dog\")\n",
    "persian_cat_weighted_template = compute_weighted_template(persian_cat_train, \"Persian Cat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874310a6",
   "metadata": {},
   "source": [
    "##### The above analysis shows the average and optimally weighted template are almost the same and thus we will arbitrarily continue the rest of the analysis with the optimally weighted template."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d559f169",
   "metadata": {},
   "source": [
    "## 5. Classification Probability Distribution and Errors with Different Ranks and Norms, Testing Against Optimally Weighted Template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5a1283",
   "metadata": {},
   "source": [
    "### Function to compute low rank approximations of the test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c4e549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_k_approx(rank, test_images):\n",
    "   new_test_images = np.zeros(test_images.shape)\n",
    "\n",
    "\n",
    "   for i in range(test_images.shape[0]):\n",
    "     test_img = test_images[i]\n",
    "     # Compute low-rank approximation of the test image\n",
    "     U, S, VT = svd(test_img, full_matrices=False)\n",
    "     U_k = U[:, :rank]\n",
    "     S_k = np.diag(S[:rank])\n",
    "     VT_k = VT[:rank, :]\n",
    "     test_img_approx = np.dot(U_k, np.dot(S_k, VT_k))\n",
    "\n",
    "\n",
    "     new_test_images[i] = test_img_approx\n",
    "\n",
    "   return new_test_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69266c77",
   "metadata": {},
   "source": [
    "### Function to store the classification margin and errors when comparing the categorical template to the low rank approximation of the test set, iterating on rank of the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bddcd24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
